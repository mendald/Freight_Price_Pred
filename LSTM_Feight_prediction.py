# -*- coding: utf-8 -*-
"""Freight.Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18TTjd36KUl-gAAQZ5TVrdyQ3aNEzjhhH
"""

import math
import pandas_datareader as web
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt

from google.colab import files
uploaded = files.upload()

import io
DF = pd.read_excel(io.BytesIO(uploaded['Freightos Baltic Index.xlsx']))

DF = DF[['index_day', 'price_median','ticker']]
date_we_care_about = DF.index_day > '2018-01-01'
DF = DF[date_we_care_about]

print(DF)

lane_we_care_about = DF.ticker == 'FBX01'
DF = DF[lane_we_care_about]
DF

DF.set_index('index_day')['price_median'].fillna(value=None, method='backfill', axis=None, limit=7, downcast=None).plot(figsize = (16,6))

DF.shape
DF = DF[['index_day', 'price_median']]
DF = DF.set_index('index_day')

print(DF)

plt.figure(figsize=(16,8))
plt.title('Freightos Price Index')
plt.plot(DF['price_median'])
plt.xlabel('Date', fontsize=12)
plt.ylabel('Close Price Freight Rates in $', fontsize=18)
plt.show()



dataset = DF.values
training_data_length = math.ceil(len(dataset) * .8)
training_data_length

# SCALING THE DATA
scaler = MinMaxScaler(feature_range=(0,1))
scaled_data = scaler.fit_transform(dataset)
print(scaled_data.shape)

train_data = scaled_data[0:training_data_length, :]
x_train = []
y_train = []

#print(train_data.shape)
for i in range(60, len(train_data)):
  x_train.append(train_data[i-60:i,0])
  y_train.append(train_data[i,0])
  if i <= 63:
    print(i)
    print(x_train)
    print(y_train)
    print(len(train_data))    
    print()
print(len(x_train))
print(len(y_train))

# CONVERT the x_train and y_train to numpy arrays
x_train, y_train = np.array(x_train), np.array(y_train)

x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))
print(x_train.shape)

print(dataset)

# BUILD THE LSTM MODEL
model = Sequential()
model.add(LSTM(50, return_sequences= True, input_shape= (x_train.shape[1], 1)))
model.add(LSTM(50, return_sequences= False))
model.add(Dense(25))
model.add(Dense(1))

# COMPILE THE MODEL
model.compile(optimizer='adam', loss='mean_squared_error')

i# TRAIN THE MODEL
model.fit(x_train, y_train, batch_size=1, epochs=50)

# CREATE THE TESTING DATA SET
test_data = scaled_data[training_data_length - 60:,:]
# CREATE THE DATA SET x_test and y_test
x_test = []
y_test = dataset[training_data_length:,:]

for i in range(60, len(test_data)):
  x_test.append(test_data[i-60:i,0])

# CONVERT DATA TO NUMPY ARRAY FORMAT
x_test = np.array(x_test)

x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))

# GET MODEL PREDICTED PRICE VALUES
predictions = model.predict(x_test)
predictions = scaler.inverse_transform(predictions)

# GET THE ROOT MEAN SQUARED ERROR (RMSE)
RMSE = np.sqrt( np.mean(predictions - y_test)**2)

RMSE

def mean_absolute_percentage_error(y_test, predictions): 
    y_true, y_pred = np.array(y_test), np.array(predictions)
    return np.mean(np.abs((y_test - predictions) / y_test)) * 100

mean_absolute_percentage_error(y_test, predictions)

DF

train = DF[:training_data_length]
valid = DF[training_data_length:]
valid['Predictions'] = predictions

# VISUALIZING
plt.figure(figsize=(16,8))
plt.title('Model')
plt.xlabel('Date', fontsize=18)
plt.ylabel('Close Freight Price in USD', fontsize=18)
plt.plot(train['price_median'])
plt.plot(valid[['price_median', 'Predictions']])
plt.legend(['Train', 'Validation', 'Preditictions'], loc='lower right')
plt.show()

# SHOW THE VALID PREDICTED PRICES
valid



DF

